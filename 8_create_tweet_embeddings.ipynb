{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nvi9p4-xK5w9","executionInfo":{"status":"ok","timestamp":1728898833780,"user_tz":-120,"elapsed":7946,"user":{"displayName":"Melody Sepahpour-Fard","userId":"13966914170519755973"}},"outputId":"b47cbccf-6025-4bb9-dfb8-233ba7b0c5b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.2.0\n"]}],"source":["%pip install sentence-transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJ9ChGgZapH2","outputId":"2ac5b257-aec8-4b27-e1e9-c01e79580c77","executionInfo":{"status":"ok","timestamp":1728899163355,"user_tz":-120,"elapsed":16795,"user":{"displayName":"Melody Sepahpour-Fard","userId":"13966914170519755973"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]}],"source":["#import pandas as pd\n","from sentence_transformers import SentenceTransformer, util\n","from tqdm import tqdm  # Import tqdm for progress bar\n","import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIfqlClQUXXl"},"outputs":[],"source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","model =  SentenceTransformer(\"dangvantuan/sentence-camembert-base\", device=device)\n","\n","# Load the entire labelled dataset\n","df = pd.read_csv(\"data/entire_dataset_labeled_final.csv\")\n","# Filter the rows with labels == 1\n","df = df[df['labels'] == 1]\n","\n","df['created_at'] = pd.to_datetime(df['created_at'])  # Convert 'created_at' to datetime\n","df['week'] = df['created_at'].dt.strftime('%Y-%U')  # Extract the week\n","\n","# Tokenize the tweets into chunks and create embeddings\n","chunk_size = 512  # Adjust the chunk size based on the model's maximum token limit\n","embeddings = []\n","\n","# Initialize tqdm with the total number of tweets\n","progress_bar = tqdm(total=len(df), desc=\"Processing Tweets\", position=0, leave=True)\n","\n","with torch.no_grad():  # Ensure that no gradients are calculated for better performance\n","    for tweet in df['tweet_clean0']:\n","        # Tokenize the tweet into chunks\n","        tokenized_chunks = [tweet[i:i+chunk_size] for i in range(0, len(tweet), chunk_size)]\n","\n","        # Create embeddings for each chunk\n","        chunk_embeddings = [model.encode(chunk) for chunk in tokenized_chunks]\n","\n","        # Average the embeddings to get a single embedding for the entire tweet\n","        if chunk_embeddings:\n","            avg_embedding = sum(chunk_embeddings) / len(chunk_embeddings)\n","            embeddings.append(avg_embedding)\n","        else:\n","            embeddings.append([])\n","\n","        # Update the progress bar\n","        progress_bar.update(1)\n","\n","# Close the progress bar\n","progress_bar.close()\n","\n","# Assign the embeddings to the DataFrame\n","df['embeddings'] = embeddings"]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"D8eF1vhKz-oA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_pickle(\"data/df_sentenceembeddings.pkl\")"],"metadata":{"id":"gUwioksQ0NoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JzsmSUWI07qz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}